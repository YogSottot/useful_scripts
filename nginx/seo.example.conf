# nginx locations tester
# https://nginx.viraptor.info/

# seo redirects, add slash
set $my_var 0;
if (-f $request_filename) {
  set $my_var 1;
}
if (-d $request_filename) {
  set $my_var 1;
}
if ($request_uri ~ "^.*/bitrix/admin$") {
  set $my_var 1;
}
if ($request_uri ~ "^.*/index.php?") {
  set $my_var 1;
}
if ($my_var = 0) {
  rewrite ^(.*[^/])$ $1/ permanent;
}

# for robots.txt based on hostname
# serve robots.txt from root by default
location = /robots.txt {
     try_files  /robots/$host.txt /robots.txt =404;
     access_log   off;
     log_not_found off;
}

# or 
location = /robots.txt {
     # main domain
     if ($http_host = domain.tld) {
            rewrite ^/robots.txt /robots_main.php last;
        }
     # specific subdomain
         if ($http_host = kazan.domain.tld) {
            rewrite ^/robots.txt  /robots_kazan.php last;
        }
     # other subdomains
         if ($http_host ~* "^([^.]+).domain\.(.+)") {
            rewrite ^/robots.txt  /robots.php last;
        }
     # default
            rewrite ^/robots.txt  /robots.php last;
}

#location ^~ /sitemap {
            rewrite ^/sitemap(.*)\.xml /sm_gen.php last;
#}

# different sitemap for virtual subdomains
# put all sitemaps for subdomain into /sitemap/subdomain.domain.tld/ in site root
location ~* ^/sitemap(.*)\.xml {
     try_files  /sitemap/$host/$request_uri /$request_uri =404;
     access_log   off;
     log_not_found off;
}

location ~* ^/sitemap(.*)\.xml$ {
    try_files /site-maps/sitemap$1.xml =404;
    access_log off;
    log_not_found off;
}

location ~* ^/sitemap(.*)\.xml$ {
    try_files /site-maps$uri =404;
    access_log off;
    log_not_found off;
}

# for work with bot_block_lite_map.conf
if ($limit_bots = 1) {
  return  444;
}

# Accept access for merged css and js
location ~* ^/bitrix/cache/(css/.+\.css|js/.+\.js)$ {
  expires max; 
  error_page 404 /404.html;
  access_log   off;
  log_not_found off;
}

# Static content
location ~* ^/(upload|bitrix/images|bitrix/tmp) { 
  expires max;
  error_page 404 /404.html;
  access_log   off;
  log_not_found off;
}

location  ~* \.(css|js|gif|png|jpg|jpeg|ico|ogg|ttf|woff|woff2|eot|otf|txt|webp|jxr|jp2)$ {
  error_page 404 /404.html;
  expires max;
  access_log   off;
  log_not_found off;
}


# if we need logs dir with autoindex
location  /logs/ {
  error_page 404 /404.html;
  expires -1;
  access_log   off;
  log_not_found off;
  autoindex on;
  autoindex_localtime on;
satisfy any;
#allow server_ip;
deny  all;

auth_basic "Private";
auth_basic_user_file /etc/nginx/.htpasswd;
  charset utf-8;
}


# вместо блока htsecure
if ($uri !~* ^/(bitrix\/admin\/1c_exchange\.php)) {
        return 301 https://$host$request_uri;
    }
# или ip адреса бухгалтерии
if ($remote_addr !~ (1.2.3.4|5.6.7.8)) {
      return 301 https://$host$request_uri;
}

# в некоторых случаях
if ($scheme != "https") {
     return 301 https://$host$request_uri;
}

# add slash
# https://habr.com/post/272381/
#rewrite ^([^.]*[^/])$ $1/ permanent;
rewrite ^([^.\?]*[^/])$ $1/ permanent;

# mergin slashes.
merge_slashes off; # into default server only.

location ~ // {
    rewrite ^(.*?)//+(.*)$ $1/$2 permanent;
}

# конструкция для merge_slash on;
# Здесь переменная $request_uri содержит исходный uri с исходными аргументами запроса (до корректировки веб-сервером и до всяких внутренних редиректов). Конструкция ^[^?]* слева от слешей нужна, чтобы убедиться, что лишние слеши обнаружены именно в uri, а не в составе аргументов (слэши в составе аргументов не трогаем). И в самую последнюю очередь делаем 301 редирект на uri, который nginx уже самостоятельно очистил от лишних слешей (это значение содержится в переменной $uri).
if ($request_uri ~ ^[^?]*//) {
    rewrite ^ $uri permanent;
}

# Универсальный вариант, не зависящий от состояния [merge_slashes]
# Если же нужен универсальный вариант, который не зависит от состояния директивы merge_slashes, то делаем так (слэши в составе аргументов не трогаем):
if ($request_uri ~ ^(?P<left>[^?]*?)//+(?P<right>[^?]*)) {
    rewrite ^ $left/$right permanent;
}



#remove slash from html
rewrite ^(.*).html/$ $1.html permanent;

server {
    listen 80 default_server;
    server_name _;

    return 301 https://domain.tld$request_uri;
}

server {
    listen 443 default_server http2;
    server_name _;

      include bx/conf/ssl.common.conf;
      ssl_certificate         /etc/letsencrypt/live/domain.tld/fullchain.pem;
      ssl_certificate_key     /etc/letsencrypt/live/domain.tld/privkey.pem;
      ssl_trusted_certificate /etc/letsencrypt/live/domain.tld/chain.pem;
     return 301 https://domain.tld$request_uri;
}

# save subdomain when redirect
server {
  listen 80;
  server_name ~^(\w+)\.olddomain\.com$;
  return 301 $scheme://$1.doma.in$request_uri;
}

https://stackoverflow.com/a/54318446
# delete www from all domains
server {
    listen 80;
    listen 443  ssl http2;
    server_name ~^(www\.)(?<domain>.+\..+\..+)$;
    return 301 https://$domain$request_uri;
    include bx/conf/ssl.common.conf;
    ssl_certificate         /etc/letsencrypt/live/domain.tld/fullchain.pem;
    ssl_certificate_key     /etc/letsencrypt/live/domain.tld/privkey.pem;
    ssl_trusted_certificate /etc/letsencrypt/live/domain.tld/chain.pem;
}


# non-www to www w/ regex in a dedicated single server for all sites:
server {
    server_name ~^(?!www\.)(?<domain>.+)$;
    return  301 $scheme://www.$domain$request_uri;
}

# www to non-www w/ regex in a dedicated single server for all sites:
server {
    server_name ~^www\.(?<domain>.+)$;
    return  301 $scheme://$domain$request_uri;
}

# www to non-www w/ regex in a dedicated server for some sites only:
# It may be necessary to restrict the regex to cover only a couple of domains, then you can use something like this to only match www.example.org, www.example.com and www.subdomain.example.net:
server {
    server_name ~^www\.(?<domain>(?:example\.org|example\.com|subdomain\.example\.net))$;
    return  301 $scheme://$domain$request_uri;
}


##   Sprinkle if within existing server / HTTPS:
# This final solution is generally not considered to be the best practice, however, it still works and does the job.

# non-www to www:
if ($host ~ ^(?!www\.)(?<domain>.+)$) {
    return  301 $scheme://www.$domain$request_uri;
}

# www to non-www:
if ($host ~ ^www\.(?<domain>.+)$) {
    return  301 $scheme://$domain$request_uri;
}

# block bots
if ($http_user_agent ~ "(aiHitBot|AhrefsBot|BLEXBot|BUbiNG|Detectify|dotbot|facebookexternalhit|facebookexternalua|FlipboardProxy|LinkpadBot|MauiBot|MegaIndex|MJ12bot|Riddler|SemrushBot|trovitBot)"){
    return 444;
}


# htps redirect, several conditions
set $https_redirect 1;
if ($request_uri ~ "^/local/service/request.php") {
  set $https_redirect 0;
}
if ($remote_addr ~ (1.2.3.4|192.168.1.2)) {
  set $https_redirect 0;
}
if ($https_redirect = 1) {
  return 301 https://$host$request_uri;
}


# remove trailing question mark
if ($request_uri ~ ^(.*)\?$) { return 301 $1; }
